{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaae1083",
   "metadata": {},
   "source": [
    "\n",
    "# Multiple horizons predictive modeling\n",
    "\n",
    "## Environment setup\n",
    "\n",
    "We need to install some extra dependencies for this notebook if needed (when\n",
    "running jupyterlite). We need the development version of skrub to be able to\n",
    "use the skrub expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e36d3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q https://pypi.anaconda.org/ogrisel/simple/polars/1.24.0/polars-1.24.0-cp39-abi3-emscripten_3_1_58_wasm32.whl\n",
    "%pip install -q https://pypi.anaconda.org/ogrisel/simple/skrub/0.6.dev0/skrub-0.6.dev0-py3-none-any.whl\n",
    "%pip install -q altair holidays plotly nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef529859",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import warnings\n",
    "\n",
    "import altair\n",
    "import cloudpickle\n",
    "import pyarrow  # noqa: F401\n",
    "import tzdata  # noqa: F401\n",
    "\n",
    "from tutorial_helpers import plot_horizon_forecast\n",
    "\n",
    "# Ignore warnings from pkg_resources triggered by Python 3.13's multiprocessing.\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"pkg_resources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d568d3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "with open(\"feature_engineering_pipeline.pkl\", \"rb\") as f:\n",
    "    feature_engineering_pipeline = cloudpickle.load(f)\n",
    "\n",
    "\n",
    "features = feature_engineering_pipeline[\"features\"]\n",
    "targets = feature_engineering_pipeline[\"targets\"]\n",
    "prediction_time = feature_engineering_pipeline[\"prediction_time\"]\n",
    "horizons = feature_engineering_pipeline[\"horizons\"]\n",
    "target_column_name_pattern = feature_engineering_pipeline[\"target_column_name_pattern\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca68ce6b",
   "metadata": {},
   "source": [
    "\n",
    "## Predicting multiple horizons with a grid of single output models\n",
    "\n",
    "Usually, it is really common to predict values for multiple horizons at once. The most\n",
    "naive approach is to train as many models as there are horizons. To achieve this,\n",
    "scikit-learn provides a meta-estimator called `MultiOutputRegressor` that can be used\n",
    "to train a single model that predicts multiple horizons at once.\n",
    "\n",
    "In short, we only need to provide multiple targets where each column corresponds to\n",
    "an horizon and this meta-estimator will train an independent model for each column.\n",
    "However, we could expect that the quality of the forecast might degrade as the horizon\n",
    "increases.\n",
    "\n",
    "Let's train a gradient boosting regressor for each horizon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c95a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "multioutput_predictions = features.skb.apply(\n",
    "    MultiOutputRegressor(\n",
    "        estimator=HistGradientBoostingRegressor(random_state=0), n_jobs=-1\n",
    "    ),\n",
    "    y=targets.skb.drop(cols=[\"prediction_time\", \"load_mw\"]).skb.mark_as_y(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68099d0d",
   "metadata": {},
   "source": [
    "\n",
    "Now, let's just rename the columns for the predictions to make it easier to plot\n",
    "the horizon forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaf6721",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column_names = [target_column_name_pattern.format(horizon=h) for h in horizons]\n",
    "predicted_target_column_names = [\n",
    "    f\"predicted_{target_column_name}\" for target_column_name in target_column_names\n",
    "]\n",
    "named_predictions = multioutput_predictions.rename(\n",
    "    {k: v for k, v in zip(target_column_names, predicted_target_column_names)}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819bca57",
   "metadata": {},
   "source": [
    "\n",
    "Let's plot the horizon forecast on a training data to check the validity of the\n",
    "output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac54420",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_at_time = datetime.datetime(2021, 4, 19, 0, 0, tzinfo=datetime.timezone.utc)\n",
    "plot_horizon_forecast(\n",
    "    targets,\n",
    "    named_predictions,\n",
    "    plot_at_time,\n",
    "    target_column_name_pattern,\n",
    ").skb.preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2badaed",
   "metadata": {},
   "source": [
    "\n",
    "On this curve, the red line corresponds to the observed values past to the the date\n",
    "for which we would like to forecast. The orange line corresponds to the observed\n",
    "values for the next 24 hours and the blue line corresponds to the predicted values\n",
    "for the next 24 hours.\n",
    "\n",
    "Since we are using a strong model and very few training data to check the validity\n",
    "we observe that our model perfectly fits the training data.\n",
    "\n",
    "So, we are now ready to assess the performance of this multi-output model and we need\n",
    "to cross-validate it. Since we do not want to aggregate the metrics for the different\n",
    "horizons, we need to create a scikit-learn scorer in which we set\n",
    "`multioutput=\"raw_values\"` to get the scores for each horizon.\n",
    "\n",
    "Passing this scorer to the `cross_validate` function returns all horizons scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7c419f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "\n",
    "max_train_size = 2 * 52 * 24 * 7  # max ~2 years of training data\n",
    "test_size = 24 * 7 * 24  # 24 weeks of test data\n",
    "gap = 7 * 24  # 1 week gap between train and test sets\n",
    "ts_cv_5 = TimeSeriesSplit(\n",
    "    n_splits=5, max_train_size=max_train_size, test_size=test_size, gap=gap\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5c1c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error\n",
    "\n",
    "\n",
    "def multioutput_scorer(regressor, X, y, score_func, score_name):\n",
    "    y_pred = regressor.predict(X)\n",
    "    return {\n",
    "        f\"{score_name}_horizon_{h}h\": score\n",
    "        for h, score in enumerate(\n",
    "            score_func(y, y_pred, multioutput=\"raw_values\"), start=1\n",
    "        )\n",
    "    }\n",
    "\n",
    "\n",
    "def scoring(regressor, X, y):\n",
    "    return {\n",
    "        **multioutput_scorer(regressor, X, y, mean_absolute_percentage_error, \"mape\"),\n",
    "        **multioutput_scorer(regressor, X, y, r2_score, \"r2\"),\n",
    "    }\n",
    "\n",
    "\n",
    "multioutput_cv_results = multioutput_predictions.skb.cross_validate(\n",
    "    cv=ts_cv_5,\n",
    "    scoring=scoring,\n",
    "    return_train_score=True,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60343be",
   "metadata": {},
   "source": [
    "\n",
    "One thing that we observe is that training such multi-output model is expensive. It is\n",
    "expected since each horizon involves a different model and thus a training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ef68b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "multioutput_cv_results.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c46a09",
   "metadata": {},
   "source": [
    "\n",
    "Instead of reading the results in the table, we can plot the scores depending on the\n",
    "type of data and the metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69712f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from IPython.display import display\n",
    "\n",
    "for metric_name, dataset_type in itertools.product([\"mape\", \"r2\"], [\"train\", \"test\"]):\n",
    "    columns = multioutput_cv_results.columns[\n",
    "        multioutput_cv_results.columns.str.startswith(f\"{dataset_type}_{metric_name}\")\n",
    "    ]\n",
    "    data_to_plot = multioutput_cv_results[columns]\n",
    "    data_to_plot.columns = [\n",
    "        col.replace(f\"{dataset_type}_\", \"\")\n",
    "        .replace(f\"{metric_name}_\", \"\")\n",
    "        .replace(\"_\", \" \")\n",
    "        for col in columns\n",
    "    ]\n",
    "\n",
    "    data_long = data_to_plot.melt(var_name=\"horizon\", value_name=\"score\")\n",
    "    chart = (\n",
    "        altair.Chart(\n",
    "            data_long,\n",
    "            title=f\"{dataset_type.title()} {metric_name.upper()} scores by horizon\",\n",
    "        )\n",
    "        .mark_boxplot(extent=\"min-max\")\n",
    "        .encode(\n",
    "            x=altair.X(\n",
    "                \"horizon:N\",\n",
    "                title=\"Horizon\",\n",
    "                sort=altair.Sort(\n",
    "                    [f\"horizon {h}h\" for h in range(1, data_to_plot.shape[1])]\n",
    "                ),\n",
    "            ),\n",
    "            y=altair.Y(\"score:Q\", title=f\"{metric_name.upper()} Score\"),\n",
    "            color=altair.Color(\"horizon:N\", legend=None),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    display(chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17918949",
   "metadata": {},
   "source": [
    "\n",
    "An interesting and unexpected observation is that the MAPE error on the test\n",
    "data is first increases and then decreases once past the horizon 18h. We\n",
    "would not necessarily expect this behaviour.\n",
    "\n",
    "## Native multi-output handling using `RandomForestRegressor`\n",
    "\n",
    "In the previous section, we showed how to wrap a `HistGradientBoostingRegressor`\n",
    "in a `MultiOutputRegressor` to predict multiple horizons. With such a strategy, it\n",
    "means that we trained independent `HistGradientBoostingRegressor`, one for each\n",
    "horizon.\n",
    "\n",
    "`RandomForestRegressor` natively supports multi-output regression: instead of\n",
    "independently training a model per horizon, it will train a joint model that\n",
    "predicts all horizons at once.\n",
    "\n",
    "Repeat the previous analysis using a `RandomForestRegressor`. Fix the parameter\n",
    "`min_samples_leaf` to 30 to limit the depth.\n",
    "\n",
    "Once you created the model, plot the horizon forecast for a given date and time.\n",
    "In addition, compute the cross-validated predictions and plot the R2 and MAPE\n",
    "scores for each horizon.\n",
    "\n",
    "Does this model perform better or worse than the previous model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a57665",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1c5345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here.\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e25640",
   "metadata": {},
   "outputs": [],
   "source": [
    "multioutput_predictions_rf = features.skb.apply(\n",
    "    RandomForestRegressor(min_samples_leaf=30, random_state=0, n_jobs=-1),\n",
    "    y=targets.skb.drop(cols=[\"prediction_time\", \"load_mw\"]).skb.mark_as_y(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cec37c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "named_predictions_rf = multioutput_predictions_rf.rename(\n",
    "    {k: v for k, v in zip(target_column_names, predicted_target_column_names)}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272d28b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_at_time = datetime.datetime(2021, 4, 24, 0, 0, tzinfo=datetime.timezone.utc)\n",
    "plot_horizon_forecast(\n",
    "    targets,\n",
    "    named_predictions_rf,\n",
    "    plot_at_time,\n",
    "    target_column_name_pattern,\n",
    ").skb.preview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0693f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "multioutput_cv_results_rf = multioutput_predictions_rf.skb.cross_validate(\n",
    "    cv=ts_cv_5,\n",
    "    scoring=scoring,\n",
    "    return_train_score=True,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d94750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "multioutput_cv_results_rf.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b36ed3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from IPython.display import display\n",
    "\n",
    "for metric_name, dataset_type in itertools.product([\"mape\", \"r2\"], [\"train\", \"test\"]):\n",
    "    columns = multioutput_cv_results_rf.columns[\n",
    "        multioutput_cv_results_rf.columns.str.startswith(\n",
    "            f\"{dataset_type}_{metric_name}\"\n",
    "        )\n",
    "    ]\n",
    "    data_to_plot = multioutput_cv_results_rf[columns]\n",
    "    data_to_plot.columns = [\n",
    "        col.replace(f\"{dataset_type}_\", \"\")\n",
    "        .replace(f\"{metric_name}_\", \"\")\n",
    "        .replace(\"_\", \" \")\n",
    "        for col in columns\n",
    "    ]\n",
    "\n",
    "    data_long = data_to_plot.melt(var_name=\"horizon\", value_name=\"score\")\n",
    "    chart = (\n",
    "        altair.Chart(\n",
    "            data_long,\n",
    "            title=f\"{dataset_type.title()} {metric_name.upper()} Scores by Horizon\",\n",
    "        )\n",
    "        .mark_boxplot(extent=\"min-max\")\n",
    "        .encode(\n",
    "            x=altair.X(\n",
    "                \"horizon:N\",\n",
    "                title=\"Horizon\",\n",
    "                sort=altair.Sort(\n",
    "                    [f\"horizon {h}h\" for h in range(1, data_to_plot.shape[1])]\n",
    "                ),\n",
    "            ),\n",
    "            y=altair.Y(\"score:Q\", title=f\"{metric_name.upper()} Score\"),\n",
    "            color=altair.Color(\"horizon:N\", legend=None),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    display(chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9b89cc",
   "metadata": {},
   "source": [
    "\n",
    "We observe that the performance of the `RandomForestRegressor` is not better in terms\n",
    "of scores or computational cost. The trend of the scores along the horizon is also\n",
    "different from the `HistGradientBoostingRegressor`: the scores worsen as the horizon\n",
    "increases."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
