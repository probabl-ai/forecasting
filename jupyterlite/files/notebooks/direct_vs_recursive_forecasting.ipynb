{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2125ad44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "SEGMENT_LENGTH = 30\n",
    "\n",
    "\n",
    "def generate_synthetic_1(\n",
    "    segment_length=SEGMENT_LENGTH,\n",
    "    n_segments=100,\n",
    "    low_noise_level=0.01,\n",
    "    high_noise_level=0.1,\n",
    "    seed=None,\n",
    "):\n",
    "    \"\"\"Generate synthetic time series data with two types of segments\n",
    "\n",
    "    - segment type \"a\" has a prefix centered around 0 and a suffix centered\n",
    "      around 1.\n",
    "    - segment type \"b\" has a prefix centered around 0 with high variance and a\n",
    "      suffix centered around -1.\n",
    "\n",
    "    The variance of the prefix is therefore predictive of the suffix.\n",
    "\n",
    "    The suffix values predictive of the next segment prefix's mean (always 0).\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    total_length = segment_length * n_segments\n",
    "    segment_types = rng.choice([\"a\", \"b\"], n_segments)\n",
    "    prefix_length = segment_length // 2\n",
    "    suffix_length = segment_length - prefix_length\n",
    "\n",
    "    segments = []\n",
    "    for segment_type in segment_types:\n",
    "        if segment_type == \"a\":\n",
    "            # Prefix is centered around 0 with low variance\n",
    "            segments.append(\n",
    "                rng.normal(loc=0, scale=low_noise_level, size=prefix_length)\n",
    "            )\n",
    "            # Suffix is centered around 1 with low variance\n",
    "            segments.append(\n",
    "                rng.normal(loc=1, scale=low_noise_level, size=suffix_length)\n",
    "            )\n",
    "        elif segment_type == \"b\":\n",
    "            # Prefix is also centered around 0 but with high variance\n",
    "            segments.append(\n",
    "                rng.normal(loc=0, scale=high_noise_level, size=prefix_length)\n",
    "            )\n",
    "            # Suffix is centered around -1 with low variance\n",
    "            segments.append(\n",
    "                rng.normal(loc=-1, scale=low_noise_level, size=suffix_length)\n",
    "            )\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"time\": np.arange(total_length),\n",
    "            \"y\": np.concatenate(segments),\n",
    "            \"series_id\": np.zeros(total_length, dtype=np.int32),\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "data = generate_synthetic_1(n_segments=1000, seed=1)\n",
    "cutoff = -SEGMENT_LENGTH * 10  # 10 segments for testing\n",
    "data_train = data.iloc[:cutoff]\n",
    "data_test = data.iloc[cutoff:]\n",
    "_ = data_train.plot(x=\"time\", y=\"y\", title=\"Synthetic data 1\", figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8926eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = data_train.iloc[: SEGMENT_LENGTH * 10].plot(\n",
    "    x=\"time\",\n",
    "    y=\"y\",\n",
    "    title=\"Synthetic data 1 - First points of training set\",\n",
    "    figsize=(15, 5),\n",
    ")\n",
    "\n",
    "_ = data_test.iloc[: SEGMENT_LENGTH * 10].plot(\n",
    "    x=\"time\",\n",
    "    y=\"y\",\n",
    "    title=\"Synthetic data 1 - First points of testing set\",\n",
    "    figsize=(15, 5),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa207f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlforecast import MLForecast\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import SplineTransformer, PolynomialFeatures\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from mlforecast.lag_transforms import (\n",
    "    Combine,\n",
    "    RollingMax,\n",
    "    RollingMin,\n",
    "    RollingMean,\n",
    "    RollingStd,\n",
    ")\n",
    "from mlforecast.target_transforms import Differences\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, module=\"sklearn\")\n",
    "\n",
    "\n",
    "mlf = MLForecast(\n",
    "    models=[\n",
    "        # Ridge(alpha=1e-6),\n",
    "        # make_pipeline(SplineTransformer(), Ridge(alpha=1e-6)),\n",
    "        # make_pipeline(\n",
    "        #     SplineTransformer(sparse_output=True, n_knots=10),\n",
    "        #     PolynomialFeatures(degree=2, include_bias=False, interaction_only=True),\n",
    "        #     # Nystroem(kernel=\"poly\", n_components=200, degree=2, random_state=0),\n",
    "        #     SelectKBest(k=100),\n",
    "        #     Ridge(alpha=1e-6),\n",
    "        # ),\n",
    "        # RandomForestRegressor(\n",
    "        #     n_estimators=100,\n",
    "        #     max_features=0.8,\n",
    "        #     max_depth=8,\n",
    "        #     min_samples_leaf=300,\n",
    "        #     n_jobs=4,\n",
    "        # ),\n",
    "        # DecisionTreeRegressor(max_depth=8, min_samples_leaf=300),\n",
    "        HistGradientBoostingRegressor(),\n",
    "    ],\n",
    "    freq=1,\n",
    "    lags=range(1, SEGMENT_LENGTH + 1),\n",
    "    lag_transforms={\n",
    "        1: [\n",
    "            RollingMean(SEGMENT_LENGTH // 2),\n",
    "            RollingStd(SEGMENT_LENGTH // 2),\n",
    "        ],\n",
    "        SEGMENT_LENGTH\n",
    "        // 2: [\n",
    "            RollingMax(SEGMENT_LENGTH // 2),\n",
    "            RollingMin(SEGMENT_LENGTH // 2),\n",
    "        ],\n",
    "    },\n",
    "    # target_transforms=[Differences([1])],\n",
    "    num_threads=4,\n",
    ")\n",
    "schema = dict(\n",
    "    time_col=\"time\",\n",
    "    id_col=\"series_id\",\n",
    "    target_col=\"y\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadd2cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlf.preprocess(data_train, **schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c824b7cc",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "PREDICTION_HORIZON = SEGMENT_LENGTH * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9738be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlf.fit(data_train, max_horizon=PREDICTION_HORIZON, **schema) # direct forecasting\n",
    "mlf.fit(data_train, **schema)  # recursive forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0584a049",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "test_offset = 0\n",
    "\n",
    "all_predictions = []\n",
    "UPDATE_CHUNK_SIZE = 5\n",
    "while test_offset < len(data_test):\n",
    "\n",
    "    new_predictions = mlf.predict(PREDICTION_HORIZON)\n",
    "    all_predictions.append(new_predictions)\n",
    "\n",
    "    # Update the forecaster with the new observations\n",
    "    mlf.update(data_test.iloc[test_offset : test_offset + UPDATE_CHUNK_SIZE])\n",
    "    test_offset += UPDATE_CHUNK_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad649c6",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "nrows = 12\n",
    "fig, axes = plt.subplots(nrows=nrows, figsize=(15, 5 * nrows))\n",
    "for row_idx, predictions in enumerate(all_predictions):\n",
    "    merged_data = data_test.copy()\n",
    "    merged_data = merged_data.merge(predictions, on=[\"time\", \"series_id\"], how=\"left\")\n",
    "\n",
    "    merged_data.drop([\"series_id\"], axis=1).iloc[: SEGMENT_LENGTH * 3].plot(\n",
    "        x=\"time\", ax=axes[row_idx]\n",
    "    )\n",
    "    axes[row_idx].set_ylim(-1.2, 1.2)\n",
    "\n",
    "    if row_idx >= nrows - 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542c2b12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
